#!/usr/bin/env python3
"""
RF Arsenal OS - Cloud Security Assessment Module
=================================================

Professional cloud infrastructure security testing with stealth-first design.
Comprehensive assessment for AWS, Azure, GCP misconfigurations and vulnerabilities.

CAPABILITIES:
- AWS S3 bucket enumeration and permission testing
- AWS IAM policy analysis and privilege escalation paths
- Azure blob storage security assessment
- GCP storage bucket testing
- Cloud metadata service exploitation
- Serverless function security testing
- Cloud credential extraction and validation

README COMPLIANCE:
- Stealth-First: Minimal API calls, randomized timing
- RAM-Only: All findings stored in memory only
- No Telemetry: Zero external data transmission
- Offline-First: Configuration analysis works offline

Author: RF Arsenal Security Team
License: Authorized Security Testing Only
"""

import asyncio
import base64
import hashlib
import hmac
import json
import logging
import os
import random
import re
import secrets
import ssl
import time
import urllib.parse
from collections import defaultdict
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Callable, Dict, List, Optional, Set, Tuple, Union
from xml.etree import ElementTree

# Optional dependencies with graceful fallback
try:
    import aiohttp
    AIOHTTP_AVAILABLE = True
except ImportError:
    AIOHTTP_AVAILABLE = False

logger = logging.getLogger(__name__)


# =============================================================================
# ENUMS AND DATA CLASSES
# =============================================================================

class CloudProvider(Enum):
    """Supported cloud providers"""
    AWS = "aws"
    AZURE = "azure"
    GCP = "gcp"
    DIGITALOCEAN = "digitalocean"
    ALIBABA = "alibaba"
    ORACLE = "oracle"


class CloudVulnType(Enum):
    """Cloud vulnerability types"""
    # Storage
    S3_PUBLIC_READ = "s3_public_read"
    S3_PUBLIC_WRITE = "s3_public_write"
    S3_PUBLIC_ACL = "s3_public_acl"
    S3_VERSIONING_DISABLED = "s3_versioning_disabled"
    S3_ENCRYPTION_DISABLED = "s3_encryption_disabled"
    S3_LOGGING_DISABLED = "s3_logging_disabled"
    AZURE_BLOB_PUBLIC = "azure_blob_public_access"
    GCP_BUCKET_PUBLIC = "gcp_bucket_public_access"
    # IAM
    IAM_WILDCARD_POLICY = "iam_wildcard_policy"
    IAM_ADMIN_ACCESS = "iam_admin_access"
    IAM_PRIVILEGE_ESCALATION = "iam_privilege_escalation"
    IAM_ROLE_CHAINING = "iam_role_chaining"
    IAM_CROSS_ACCOUNT = "iam_cross_account_access"
    IAM_EXPOSED_CREDENTIALS = "iam_exposed_credentials"
    # Compute
    IMDS_EXPOSED = "imds_exposed"
    IMDS_V1_ENABLED = "imds_v1_enabled"
    EC2_USER_DATA_SECRETS = "ec2_user_data_secrets"
    LAMBDA_ENV_SECRETS = "lambda_env_secrets"
    # Network
    SECURITY_GROUP_OPEN = "security_group_open"
    VPC_FLOW_LOGS_DISABLED = "vpc_flow_logs_disabled"
    PUBLIC_SNAPSHOT = "public_snapshot"
    # Serverless
    LAMBDA_PUBLIC = "lambda_public_access"
    API_GATEWAY_OPEN = "api_gateway_open"
    # Database
    RDS_PUBLIC = "rds_public_access"
    RDS_ENCRYPTION_DISABLED = "rds_encryption_disabled"
    DYNAMODB_ENCRYPTION_DISABLED = "dynamodb_encryption_disabled"
    # Secrets
    SECRET_IN_CODE = "secret_in_code"
    HARDCODED_CREDENTIALS = "hardcoded_credentials"
    # Misconfiguration
    CLOUDTRAIL_DISABLED = "cloudtrail_disabled"
    MFA_DISABLED = "mfa_disabled"
    ROOT_ACCOUNT_USED = "root_account_used"


class SeverityLevel(Enum):
    """Vulnerability severity levels"""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "informational"


class BucketPermission(Enum):
    """S3/Storage bucket permissions"""
    PRIVATE = "private"
    PUBLIC_READ = "public-read"
    PUBLIC_READ_WRITE = "public-read-write"
    AUTHENTICATED_READ = "authenticated-read"
    UNKNOWN = "unknown"


@dataclass
class CloudVulnerability:
    """Detected cloud vulnerability"""
    vuln_type: CloudVulnType
    severity: SeverityLevel
    provider: CloudProvider
    resource: str
    region: str
    description: str
    evidence: Optional[str] = None
    remediation: str = ""
    confidence: float = 0.0
    cwe_id: Optional[str] = None
    timestamp: datetime = field(default_factory=datetime.now)
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for reporting"""
        return {
            'type': self.vuln_type.value,
            'severity': self.severity.value,
            'provider': self.provider.value,
            'resource': self.resource,
            'region': self.region,
            'description': self.description,
            'evidence': self.evidence[:1000] if self.evidence else None,
            'remediation': self.remediation,
            'confidence': self.confidence,
            'cwe_id': self.cwe_id,
            'timestamp': self.timestamp.isoformat(),
            'metadata': self.metadata,
        }


@dataclass
class S3Bucket:
    """S3 bucket information"""
    name: str
    region: str = "unknown"
    exists: bool = False
    permission: BucketPermission = BucketPermission.UNKNOWN
    objects: List[str] = field(default_factory=list)
    size: int = 0
    versioning: bool = False
    encryption: bool = False
    logging: bool = False
    website_enabled: bool = False
    cors_enabled: bool = False
    acl: Optional[Dict] = None


@dataclass
class IAMPolicy:
    """IAM policy structure"""
    name: str
    arn: Optional[str] = None
    version: str = "2012-10-17"
    statements: List[Dict] = field(default_factory=list)
    is_dangerous: bool = False
    dangerous_actions: List[str] = field(default_factory=list)
    privilege_escalation_paths: List[str] = field(default_factory=list)


@dataclass
class CloudCredential:
    """Cloud credential"""
    provider: CloudProvider
    credential_type: str
    value: str
    is_valid: bool = False
    permissions: List[str] = field(default_factory=list)
    expiry: Optional[datetime] = None
    source: Optional[str] = None


@dataclass
class CloudSecurityConfig:
    """Cloud security assessment configuration"""
    # Target
    providers: List[CloudProvider] = field(default_factory=lambda: [CloudProvider.AWS])
    regions: List[str] = field(default_factory=lambda: ["us-east-1", "us-west-2", "eu-west-1"])
    
    # AWS settings
    aws_access_key: Optional[str] = None
    aws_secret_key: Optional[str] = None
    aws_session_token: Optional[str] = None
    
    # Azure settings
    azure_tenant_id: Optional[str] = None
    azure_client_id: Optional[str] = None
    azure_client_secret: Optional[str] = None
    
    # GCP settings
    gcp_project_id: Optional[str] = None
    gcp_credentials_json: Optional[str] = None
    
    # Bucket enumeration
    bucket_wordlist: List[str] = field(default_factory=list)
    bucket_permutations: bool = True
    
    # Stealth settings
    delay_min: float = 1.0
    delay_max: float = 3.0
    randomize_timing: bool = True
    use_proxy: bool = False
    proxy_url: Optional[str] = None
    
    # Test modules
    test_buckets: bool = True
    test_iam: bool = True
    test_imds: bool = True
    test_serverless: bool = True
    test_network: bool = True
    
    # Limits
    timeout: float = 30.0
    max_buckets: int = 100
    max_objects_per_bucket: int = 50


# =============================================================================
# AWS SECURITY SCANNER
# =============================================================================

class AWSSecurityScanner:
    """
    AWS Security Scanner
    
    Capabilities:
    - S3 bucket enumeration and permission testing
    - IAM policy analysis
    - EC2 metadata service testing
    - Lambda/Serverless security
    
    README COMPLIANCE:
    - Stealth-First: Minimal API calls
    - RAM-Only: No persistent storage
    - No Telemetry: Zero external reporting
    """
    
    # AWS regions
    AWS_REGIONS = [
        "us-east-1", "us-east-2", "us-west-1", "us-west-2",
        "eu-west-1", "eu-west-2", "eu-west-3", "eu-central-1",
        "ap-southeast-1", "ap-southeast-2", "ap-northeast-1",
        "ap-northeast-2", "ap-south-1", "sa-east-1",
        "ca-central-1", "eu-north-1", "me-south-1",
    ]
    
    # S3 URL formats
    S3_URL_FORMATS = [
        "https://{bucket}.s3.amazonaws.com",
        "https://{bucket}.s3.{region}.amazonaws.com",
        "https://s3.{region}.amazonaws.com/{bucket}",
        "https://s3.amazonaws.com/{bucket}",
    ]
    
    # Common bucket name patterns
    BUCKET_PATTERNS = [
        "{company}-backup", "{company}-backups", "{company}-data",
        "{company}-assets", "{company}-static", "{company}-media",
        "{company}-files", "{company}-uploads", "{company}-images",
        "{company}-logs", "{company}-archive", "{company}-dev",
        "{company}-staging", "{company}-prod", "{company}-production",
        "{company}-test", "{company}-private", "{company}-public",
        "{company}-internal", "{company}-external", "{company}-config",
        "{company}-secrets", "{company}-keys", "{company}-db-backup",
        "backup-{company}", "data-{company}", "files-{company}",
    ]
    
    # Dangerous IAM actions for privilege escalation
    DANGEROUS_IAM_ACTIONS = [
        "iam:CreateAccessKey",
        "iam:CreateLoginProfile",
        "iam:UpdateLoginProfile",
        "iam:AttachUserPolicy",
        "iam:AttachGroupPolicy",
        "iam:AttachRolePolicy",
        "iam:PutUserPolicy",
        "iam:PutGroupPolicy",
        "iam:PutRolePolicy",
        "iam:CreatePolicy",
        "iam:CreatePolicyVersion",
        "iam:SetDefaultPolicyVersion",
        "iam:PassRole",
        "iam:CreateRole",
        "iam:UpdateRole",
        "iam:UpdateAssumeRolePolicy",
        "sts:AssumeRole",
        "lambda:CreateFunction",
        "lambda:InvokeFunction",
        "lambda:UpdateFunctionCode",
        "lambda:AddPermission",
        "ec2:RunInstances",
        "cloudformation:CreateStack",
        "glue:CreateDevEndpoint",
        "glue:UpdateDevEndpoint",
        "datapipeline:CreatePipeline",
        "ssm:SendCommand",
    ]
    
    # Credential patterns
    AWS_KEY_PATTERNS = [
        r'AKIA[0-9A-Z]{16}',  # Access Key ID
        r'ASIA[0-9A-Z]{16}',  # Temporary Access Key ID
        r'(?<![A-Za-z0-9/+=])[A-Za-z0-9/+=]{40}(?![A-Za-z0-9/+=])',  # Secret Key
    ]
    
    def __init__(self, config: Optional[CloudSecurityConfig] = None):
        """Initialize AWS security scanner"""
        self.config = config or CloudSecurityConfig()
        self.vulnerabilities: List[CloudVulnerability] = []
        self.buckets: List[S3Bucket] = []
        self.credentials: List[CloudCredential] = []
        self.stats = defaultdict(int)
        self._running = False
        self._lock = asyncio.Lock()
        self._authorized = False
        
        logger.info("AWSSecurityScanner initialized - RAM-only, stealth mode")
    
    def authorize(self, confirmation: str = "I_AUTHORIZE_CLOUD_TESTING") -> bool:
        """Authorize cloud security testing"""
        if confirmation == "I_AUTHORIZE_CLOUD_TESTING":
            self._authorized = True
            logger.info("Cloud security testing authorized")
            return True
        return False
    
    async def _delay(self):
        """Apply stealth delay"""
        if self.config.randomize_timing:
            delay = random.uniform(self.config.delay_min, self.config.delay_max)
            await asyncio.sleep(delay)
    
    async def _make_request(
        self,
        url: str,
        method: str = "GET",
        headers: Optional[Dict] = None,
        data: Optional[bytes] = None,
    ) -> Tuple[Optional[int], Optional[str], Optional[Dict]]:
        """Make HTTP request with stealth"""
        if not AIOHTTP_AVAILABLE:
            return None, None, None
        
        await self._delay()
        
        try:
            ssl_context = ssl.create_default_context()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE
            
            timeout = aiohttp.ClientTimeout(total=self.config.timeout)
            
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.request(
                    method, url,
                    headers=headers,
                    data=data,
                    ssl=ssl_context,
                ) as response:
                    text = await response.text()
                    self.stats['requests'] += 1
                    return response.status, text, dict(response.headers)
        
        except Exception as e:
            self.stats['errors'] += 1
            logger.debug(f"Request error: {e}")
            return None, None, None
    
    async def _add_vulnerability(self, vuln: CloudVulnerability):
        """Add vulnerability (thread-safe)"""
        async with self._lock:
            for existing in self.vulnerabilities:
                if (existing.vuln_type == vuln.vuln_type and
                    existing.resource == vuln.resource):
                    return
            
            self.vulnerabilities.append(vuln)
            self.stats['vulnerabilities'] += 1
            logger.info(f"[{vuln.severity.value.upper()}] {vuln.vuln_type.value}: {vuln.resource}")
    
    # =========================================================================
    # S3 BUCKET ENUMERATION AND TESTING
    # =========================================================================
    
    async def enumerate_s3_buckets(
        self,
        company_names: List[str],
        custom_wordlist: Optional[List[str]] = None,
    ) -> List[S3Bucket]:
        """
        Enumerate S3 buckets using company names and patterns
        
        Args:
            company_names: List of company/target names
            custom_wordlist: Additional bucket names to test
        """
        if not self._authorized:
            logger.warning("Bucket enumeration requires authorization")
            return []
        
        buckets_to_test = set()
        
        # Generate bucket names from patterns
        for company in company_names:
            company_lower = company.lower().replace(' ', '-').replace('_', '-')
            
            # Direct names
            buckets_to_test.add(company_lower)
            buckets_to_test.add(f"{company_lower}-s3")
            buckets_to_test.add(f"s3-{company_lower}")
            
            # Pattern-based names
            for pattern in self.BUCKET_PATTERNS:
                bucket_name = pattern.format(company=company_lower)
                buckets_to_test.add(bucket_name)
            
            # Regional variations
            for region in self.config.regions[:3]:
                buckets_to_test.add(f"{company_lower}-{region}")
                buckets_to_test.add(f"{company_lower}-{region.replace('-', '')}")
        
        # Add custom wordlist
        if custom_wordlist:
            buckets_to_test.update(custom_wordlist)
        
        if self.config.bucket_wordlist:
            buckets_to_test.update(self.config.bucket_wordlist)
        
        logger.info(f"Testing {len(buckets_to_test)} potential bucket names")
        
        # Test buckets concurrently
        semaphore = asyncio.Semaphore(10)
        
        async def test_bucket(bucket_name: str) -> Optional[S3Bucket]:
            async with semaphore:
                return await self._test_s3_bucket(bucket_name)
        
        tasks = [test_bucket(name) for name in list(buckets_to_test)[:self.config.max_buckets]]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        found_buckets = []
        for result in results:
            if isinstance(result, S3Bucket) and result.exists:
                found_buckets.append(result)
                self.buckets.append(result)
        
        logger.info(f"Found {len(found_buckets)} existing buckets")
        return found_buckets
    
    async def _test_s3_bucket(self, bucket_name: str) -> S3Bucket:
        """Test a single S3 bucket for existence and permissions"""
        bucket = S3Bucket(name=bucket_name)
        
        # Try different URL formats
        for url_format in self.S3_URL_FORMATS[:2]:
            url = url_format.format(bucket=bucket_name, region="us-east-1")
            
            status, response, headers = await self._make_request(url)
            self.stats['bucket_tests'] += 1
            
            if status == 200:
                bucket.exists = True
                bucket.permission = BucketPermission.PUBLIC_READ
                
                # Try to list objects
                try:
                    if response and '<ListBucketResult' in response:
                        root = ElementTree.fromstring(response)
                        ns = {'s3': 'http://s3.amazonaws.com/doc/2006-03-01/'}
                        
                        for content in root.findall('.//s3:Contents', ns):
                            key = content.find('s3:Key', ns)
                            if key is not None and key.text:
                                bucket.objects.append(key.text)
                                if len(bucket.objects) >= self.config.max_objects_per_bucket:
                                    break
                except Exception:
                    pass
                
                # Create vulnerability for public read
                vuln = CloudVulnerability(
                    vuln_type=CloudVulnType.S3_PUBLIC_READ,
                    severity=SeverityLevel.HIGH,
                    provider=CloudProvider.AWS,
                    resource=f"s3://{bucket_name}",
                    region="us-east-1",
                    description=f"S3 bucket '{bucket_name}' allows public read access",
                    evidence=f"Found {len(bucket.objects)} objects" if bucket.objects else "Bucket listing accessible",
                    remediation="Remove public access, use bucket policies for access control",
                    confidence=0.95,
                    cwe_id="CWE-284",
                    metadata={'objects': bucket.objects[:10]},
                )
                await self._add_vulnerability(vuln)
                break
            
            elif status == 403:
                bucket.exists = True
                bucket.permission = BucketPermission.PRIVATE
                # Bucket exists but no public access - good
                break
            
            elif status == 404:
                bucket.exists = False
                break
        
        # Test public write access
        if bucket.exists:
            await self._test_s3_write_access(bucket)
        
        return bucket
    
    async def _test_s3_write_access(self, bucket: S3Bucket):
        """Test if bucket allows public write"""
        test_key = f"rf-arsenal-test-{secrets.token_hex(8)}.txt"
        url = f"https://{bucket.name}.s3.amazonaws.com/{test_key}"
        
        # Try to upload a small test file
        test_content = b"RF Arsenal security test - safe to delete"
        
        status, _, _ = await self._make_request(
            url,
            method="PUT",
            data=test_content,
            headers={"Content-Type": "text/plain"}
        )
        
        if status == 200:
            bucket.permission = BucketPermission.PUBLIC_READ_WRITE
            
            vuln = CloudVulnerability(
                vuln_type=CloudVulnType.S3_PUBLIC_WRITE,
                severity=SeverityLevel.CRITICAL,
                provider=CloudProvider.AWS,
                resource=f"s3://{bucket.name}",
                region=bucket.region,
                description=f"S3 bucket '{bucket.name}' allows public write access",
                evidence="Successfully uploaded test file",
                remediation="Immediately remove public write access, audit bucket contents",
                confidence=0.99,
                cwe_id="CWE-284",
            )
            await self._add_vulnerability(vuln)
            
            # Try to delete the test file
            await self._make_request(url, method="DELETE")
    
    async def check_bucket_acl(self, bucket_name: str) -> Optional[Dict]:
        """Check S3 bucket ACL for misconfigurations"""
        url = f"https://{bucket_name}.s3.amazonaws.com/?acl"
        
        status, response, _ = await self._make_request(url)
        
        if status == 200 and response:
            try:
                root = ElementTree.fromstring(response)
                ns = {'s3': 'http://s3.amazonaws.com/doc/2006-03-01/'}
                
                acl_data = {'grants': []}
                
                for grant in root.findall('.//s3:Grant', ns):
                    grantee = grant.find('s3:Grantee', ns)
                    permission = grant.find('s3:Permission', ns)
                    
                    if grantee is not None and permission is not None:
                        grantee_uri = grantee.find('s3:URI', ns)
                        if grantee_uri is not None:
                            grant_info = {
                                'grantee': grantee_uri.text,
                                'permission': permission.text,
                            }
                            acl_data['grants'].append(grant_info)
                            
                            # Check for AllUsers or AuthenticatedUsers
                            if 'AllUsers' in grantee_uri.text:
                                vuln = CloudVulnerability(
                                    vuln_type=CloudVulnType.S3_PUBLIC_ACL,
                                    severity=SeverityLevel.HIGH,
                                    provider=CloudProvider.AWS,
                                    resource=f"s3://{bucket_name}",
                                    region="global",
                                    description=f"S3 bucket ACL grants {permission.text} to AllUsers",
                                    evidence=f"ACL grants public {permission.text} access",
                                    remediation="Remove AllUsers from bucket ACL",
                                    confidence=0.95,
                                    cwe_id="CWE-732",
                                )
                                await self._add_vulnerability(vuln)
                
                return acl_data
            
            except Exception as e:
                logger.debug(f"Failed to parse ACL: {e}")
        
        return None
    
    # =========================================================================
    # IAM POLICY ANALYSIS
    # =========================================================================
    
    def analyze_iam_policy(self, policy_json: Union[str, Dict]) -> IAMPolicy:
        """
        Analyze IAM policy for security issues
        
        This works offline - no API calls needed
        """
        if isinstance(policy_json, str):
            policy_data = json.loads(policy_json)
        else:
            policy_data = policy_json
        
        policy = IAMPolicy(
            name=policy_data.get('PolicyName', 'Unknown'),
            version=policy_data.get('Version', '2012-10-17'),
        )
        
        statements = policy_data.get('Statement', [])
        if isinstance(statements, dict):
            statements = [statements]
        
        policy.statements = statements
        
        for statement in statements:
            effect = statement.get('Effect', '')
            actions = statement.get('Action', [])
            resources = statement.get('Resource', [])
            
            if isinstance(actions, str):
                actions = [actions]
            if isinstance(resources, str):
                resources = [resources]
            
            if effect == 'Allow':
                # Check for wildcard actions
                if '*' in actions or 'iam:*' in actions:
                    policy.is_dangerous = True
                    policy.dangerous_actions.append('Wildcard action (*)')
                
                # Check for dangerous actions
                for action in actions:
                    if action in self.DANGEROUS_IAM_ACTIONS:
                        policy.is_dangerous = True
                        policy.dangerous_actions.append(action)
                    
                    # Check for privilege escalation paths
                    if action in ['iam:CreateAccessKey', 'iam:CreateLoginProfile']:
                        policy.privilege_escalation_paths.append(
                            f"Create credentials via {action}"
                        )
                    elif action in ['iam:AttachUserPolicy', 'iam:AttachRolePolicy']:
                        policy.privilege_escalation_paths.append(
                            f"Attach admin policy via {action}"
                        )
                    elif action == 'iam:PassRole':
                        policy.privilege_escalation_paths.append(
                            "Pass privileged role to service"
                        )
                    elif action == 'lambda:CreateFunction':
                        policy.privilege_escalation_paths.append(
                            "Create Lambda with privileged role"
                        )
                    elif action == 'sts:AssumeRole':
                        policy.privilege_escalation_paths.append(
                            "Assume more privileged role"
                        )
                
                # Check for admin access
                if '*' in resources and ('*' in actions or 'iam:*' in actions):
                    policy.privilege_escalation_paths.append(
                        "Full admin access - can escalate to any permission"
                    )
        
        # Create vulnerabilities for dangerous policies
        if policy.is_dangerous:
            vuln = CloudVulnerability(
                vuln_type=CloudVulnType.IAM_WILDCARD_POLICY,
                severity=SeverityLevel.HIGH,
                provider=CloudProvider.AWS,
                resource=policy.name,
                region="global",
                description=f"IAM policy contains dangerous permissions",
                evidence=f"Dangerous actions: {', '.join(policy.dangerous_actions[:5])}",
                remediation="Apply least privilege principle, remove wildcard permissions",
                confidence=0.9,
                cwe_id="CWE-269",
                metadata={'escalation_paths': policy.privilege_escalation_paths},
            )
            self.vulnerabilities.append(vuln)
        
        if policy.privilege_escalation_paths:
            vuln = CloudVulnerability(
                vuln_type=CloudVulnType.IAM_PRIVILEGE_ESCALATION,
                severity=SeverityLevel.CRITICAL,
                provider=CloudProvider.AWS,
                resource=policy.name,
                region="global",
                description="IAM policy allows privilege escalation",
                evidence=f"Paths: {', '.join(policy.privilege_escalation_paths[:3])}",
                remediation="Remove privilege escalation vectors, use permission boundaries",
                confidence=0.85,
                cwe_id="CWE-269",
            )
            self.vulnerabilities.append(vuln)
        
        return policy
    
    # =========================================================================
    # EC2 METADATA SERVICE (IMDS) TESTING
    # =========================================================================
    
    async def test_imds_exposure(self, target_url: str) -> List[CloudVulnerability]:
        """
        Test for IMDS exposure via SSRF
        
        Args:
            target_url: URL that might be vulnerable to SSRF
        """
        vulnerabilities = []
        
        if not self._authorized:
            logger.warning("IMDS testing requires authorization")
            return vulnerabilities
        
        # IMDS endpoints to test
        imds_endpoints = [
            "http://169.254.169.254/latest/meta-data/",
            "http://169.254.169.254/latest/meta-data/iam/security-credentials/",
            "http://169.254.169.254/latest/user-data",
            "http://169.254.169.254/latest/dynamic/instance-identity/document",
            # IMDSv2 token endpoint
            "http://169.254.169.254/latest/api/token",
        ]
        
        # SSRF payloads
        ssrf_payloads = [
            "{imds}",
            "http://169.254.169.254.xip.io/latest/meta-data/",
            "http://[::ffff:169.254.169.254]/latest/meta-data/",
            "http://0xa9fea9fe/latest/meta-data/",  # Decimal IP
            "http://169.254.169.254:80/latest/meta-data/",
            "http://169.254.169.254%00/latest/meta-data/",
        ]
        
        logger.info(f"Testing IMDS exposure via {target_url}")
        
        for imds_url in imds_endpoints:
            for payload_template in ssrf_payloads:
                payload = payload_template.format(imds=imds_url)
                
                # Test via URL parameter
                if '?' in target_url:
                    test_url = f"{target_url}&url={urllib.parse.quote(payload)}"
                else:
                    test_url = f"{target_url}?url={urllib.parse.quote(payload)}"
                
                status, response, _ = await self._make_request(test_url)
                
                if status == 200 and response:
                    # Check for IMDS response indicators
                    imds_indicators = [
                        'ami-id', 'instance-id', 'instance-type',
                        'local-ipv4', 'public-ipv4', 'security-credentials',
                        'AccessKeyId', 'SecretAccessKey', 'Token',
                    ]
                    
                    if any(indicator in response for indicator in imds_indicators):
                        severity = SeverityLevel.CRITICAL
                        
                        # Check if credentials were leaked
                        if 'AccessKeyId' in response or 'SecretAccessKey' in response:
                            vuln_type = CloudVulnType.IAM_EXPOSED_CREDENTIALS
                            description = "IMDS credentials exposed via SSRF"
                        else:
                            vuln_type = CloudVulnType.IMDS_EXPOSED
                            description = "EC2 metadata exposed via SSRF"
                        
                        vuln = CloudVulnerability(
                            vuln_type=vuln_type,
                            severity=severity,
                            provider=CloudProvider.AWS,
                            resource=target_url,
                            region="unknown",
                            description=description,
                            evidence=f"Retrieved IMDS data: {response[:200]}...",
                            payload=payload,
                            remediation="Enable IMDSv2, block IMDS access from user code",
                            confidence=0.95,
                            cwe_id="CWE-918",
                        )
                        vulnerabilities.append(vuln)
                        await self._add_vulnerability(vuln)
                        break
        
        return vulnerabilities
    
    async def test_direct_imds(self, host: str = "169.254.169.254") -> List[CloudVulnerability]:
        """
        Test direct IMDS access (when running on EC2)
        """
        vulnerabilities = []
        
        # Test IMDSv1 (direct access)
        url_v1 = f"http://{host}/latest/meta-data/"
        status, response, _ = await self._make_request(url_v1)
        
        if status == 200:
            vuln = CloudVulnerability(
                vuln_type=CloudVulnType.IMDS_V1_ENABLED,
                severity=SeverityLevel.MEDIUM,
                provider=CloudProvider.AWS,
                resource="EC2 Instance",
                region="local",
                description="IMDSv1 is enabled - vulnerable to SSRF attacks",
                evidence="Successfully accessed IMDS without token",
                remediation="Enforce IMDSv2 only via instance metadata options",
                confidence=0.95,
                cwe_id="CWE-918",
            )
            vulnerabilities.append(vuln)
            await self._add_vulnerability(vuln)
            
            # Try to get credentials
            creds_url = f"http://{host}/latest/meta-data/iam/security-credentials/"
            status, response, _ = await self._make_request(creds_url)
            
            if status == 200 and response:
                role_name = response.strip()
                role_creds_url = f"{creds_url}{role_name}"
                status, creds_response, _ = await self._make_request(role_creds_url)
                
                if status == 200 and creds_response:
                    try:
                        creds_data = json.loads(creds_response)
                        if 'AccessKeyId' in creds_data:
                            vuln = CloudVulnerability(
                                vuln_type=CloudVulnType.IAM_EXPOSED_CREDENTIALS,
                                severity=SeverityLevel.CRITICAL,
                                provider=CloudProvider.AWS,
                                resource=f"IAM Role: {role_name}",
                                region="local",
                                description=f"IAM credentials accessible via IMDS",
                                evidence=f"Role: {role_name}, Key: {creds_data.get('AccessKeyId', 'N/A')[:10]}...",
                                remediation="Restrict IAM role permissions, enable IMDSv2",
                                confidence=0.99,
                                cwe_id="CWE-522",
                            )
                            vulnerabilities.append(vuln)
                            await self._add_vulnerability(vuln)
                    except json.JSONDecodeError:
                        pass
        
        return vulnerabilities
    
    # =========================================================================
    # CREDENTIAL DETECTION
    # =========================================================================
    
    def detect_aws_credentials(self, content: str, source: str = "unknown") -> List[CloudCredential]:
        """
        Detect AWS credentials in content
        
        This works offline - pattern matching only
        """
        credentials = []
        
        # Find Access Key IDs
        access_key_pattern = re.compile(r'(AKIA|ASIA)[0-9A-Z]{16}')
        for match in access_key_pattern.finditer(content):
            key_id = match.group(0)
            
            # Try to find associated secret key nearby
            start = max(0, match.start() - 200)
            end = min(len(content), match.end() + 200)
            context = content[start:end]
            
            secret_pattern = re.compile(r'[A-Za-z0-9/+=]{40}')
            secret_matches = secret_pattern.findall(context)
            
            cred = CloudCredential(
                provider=CloudProvider.AWS,
                credential_type="access_key",
                value=key_id,
                source=source,
            )
            credentials.append(cred)
            self.credentials.append(cred)
            
            vuln = CloudVulnerability(
                vuln_type=CloudVulnType.HARDCODED_CREDENTIALS,
                severity=SeverityLevel.CRITICAL,
                provider=CloudProvider.AWS,
                resource=source,
                region="global",
                description=f"AWS Access Key ID found: {key_id}",
                evidence=f"Key starts with: {key_id[:8]}...",
                remediation="Rotate credentials immediately, use IAM roles instead",
                confidence=0.95,
                cwe_id="CWE-798",
            )
            self.vulnerabilities.append(vuln)
        
        return credentials
    
    # =========================================================================
    # USER DATA SECRETS DETECTION
    # =========================================================================
    
    def analyze_user_data(self, user_data: str) -> List[CloudVulnerability]:
        """
        Analyze EC2 user data for secrets
        
        This works offline
        """
        vulnerabilities = []
        
        # Decode if base64
        try:
            decoded = base64.b64decode(user_data).decode('utf-8')
        except Exception:
            decoded = user_data
        
        # Patterns for secrets
        secret_patterns = [
            (r'(?i)password\s*[=:]\s*["\']?([^\s"\']+)', 'password'),
            (r'(?i)api[_-]?key\s*[=:]\s*["\']?([^\s"\']+)', 'api_key'),
            (r'(?i)secret\s*[=:]\s*["\']?([^\s"\']+)', 'secret'),
            (r'(?i)token\s*[=:]\s*["\']?([^\s"\']+)', 'token'),
            (r'(?i)aws[_-]?access[_-]?key[_-]?id\s*[=:]\s*["\']?([^\s"\']+)', 'aws_key'),
            (r'(?i)aws[_-]?secret[_-]?access[_-]?key\s*[=:]\s*["\']?([^\s"\']+)', 'aws_secret'),
            (r'(?i)database[_-]?password\s*[=:]\s*["\']?([^\s"\']+)', 'db_password'),
            (r'(?i)mysql[_-]?password\s*[=:]\s*["\']?([^\s"\']+)', 'mysql_password'),
            (r'(?i)postgres[_-]?password\s*[=:]\s*["\']?([^\s"\']+)', 'postgres_password'),
        ]
        
        for pattern, secret_type in secret_patterns:
            matches = re.findall(pattern, decoded)
            for match in matches:
                if len(match) > 3:  # Ignore very short matches
                    vuln = CloudVulnerability(
                        vuln_type=CloudVulnType.EC2_USER_DATA_SECRETS,
                        severity=SeverityLevel.HIGH,
                        provider=CloudProvider.AWS,
                        resource="EC2 User Data",
                        region="unknown",
                        description=f"Secret ({secret_type}) found in EC2 user data",
                        evidence=f"Found {secret_type}: {match[:10]}..." if len(match) > 10 else f"Found {secret_type}",
                        remediation="Use AWS Secrets Manager or Parameter Store instead",
                        confidence=0.85,
                        cwe_id="CWE-798",
                    )
                    vulnerabilities.append(vuln)
        
        # Check for AWS credentials
        self.detect_aws_credentials(decoded, "EC2 User Data")
        
        return vulnerabilities
    
    # =========================================================================
    # MAIN SCAN METHOD
    # =========================================================================
    
    async def scan(
        self,
        company_names: Optional[List[str]] = None,
        bucket_names: Optional[List[str]] = None,
        iam_policies: Optional[List[Dict]] = None,
        ssrf_targets: Optional[List[str]] = None,
    ) -> List[CloudVulnerability]:
        """
        Run comprehensive AWS security scan
        """
        if not self._authorized:
            logger.error("Scan not authorized. Call authorize() first.")
            return []
        
        self._running = True
        self.vulnerabilities = []
        
        logger.info("Starting AWS security scan")
        
        try:
            # S3 bucket enumeration
            if self.config.test_buckets and company_names:
                await self.enumerate_s3_buckets(company_names, bucket_names)
            
            # IAM policy analysis (offline)
            if self.config.test_iam and iam_policies:
                for policy in iam_policies:
                    self.analyze_iam_policy(policy)
            
            # IMDS testing
            if self.config.test_imds:
                await self.test_direct_imds()
                
                if ssrf_targets:
                    for target in ssrf_targets:
                        await self.test_imds_exposure(target)
        
        except Exception as e:
            logger.error(f"Scan error: {e}")
        finally:
            self._running = False
        
        logger.info(f"Scan complete. Found {len(self.vulnerabilities)} vulnerabilities")
        return self.vulnerabilities
    
    def get_stats(self) -> Dict[str, Any]:
        """Get scan statistics"""
        return {
            'requests': self.stats['requests'],
            'bucket_tests': self.stats['bucket_tests'],
            'vulnerabilities': self.stats['vulnerabilities'],
            'errors': self.stats['errors'],
            'buckets_found': len([b for b in self.buckets if b.exists]),
            'credentials_found': len(self.credentials),
        }
    
    def get_report(self, format: str = "json") -> str:
        """Generate security report"""
        if format == "json":
            return json.dumps({
                'provider': 'AWS',
                'scan_time': datetime.now().isoformat(),
                'statistics': self.get_stats(),
                'buckets': [
                    {'name': b.name, 'permission': b.permission.value, 'objects': len(b.objects)}
                    for b in self.buckets if b.exists
                ],
                'vulnerabilities': [v.to_dict() for v in self.vulnerabilities],
            }, indent=2)
        
        else:
            lines = [
                "=" * 70,
                "RF ARSENAL OS - AWS SECURITY SCAN REPORT",
                "=" * 70,
                f"Scan Time: {datetime.now().isoformat()}",
                "",
                "SUMMARY:",
                f"  Buckets Found: {len([b for b in self.buckets if b.exists])}",
                f"  Credentials Found: {len(self.credentials)}",
                f"  Vulnerabilities: {len(self.vulnerabilities)}",
                "",
                "VULNERABILITIES:",
                "-" * 50,
            ]
            
            for vuln in sorted(self.vulnerabilities, key=lambda v: list(SeverityLevel).index(v.severity)):
                lines.append(f"\n[{vuln.severity.value.upper()}] {vuln.vuln_type.value}")
                lines.append(f"  Resource: {vuln.resource}")
                lines.append(f"  Description: {vuln.description}")
                if vuln.remediation:
                    lines.append(f"  Remediation: {vuln.remediation}")
            
            return "\n".join(lines)
    
    def clear_results(self):
        """Clear all results from RAM"""
        self.vulnerabilities = []
        self.buckets = []
        self.credentials = []
        self.stats = defaultdict(int)
        logger.info("Results cleared from RAM")


# =============================================================================
# AZURE SECURITY SCANNER
# =============================================================================

class AzureSecurityScanner:
    """
    Azure Security Scanner
    
    Capabilities:
    - Blob storage enumeration
    - Storage account security
    - Azure AD analysis
    """
    
    AZURE_STORAGE_SUFFIXES = [
        ".blob.core.windows.net",
        ".file.core.windows.net",
        ".queue.core.windows.net",
        ".table.core.windows.net",
    ]
    
    def __init__(self, config: Optional[CloudSecurityConfig] = None):
        """Initialize Azure security scanner"""
        self.config = config or CloudSecurityConfig()
        self.vulnerabilities: List[CloudVulnerability] = []
        self.stats = defaultdict(int)
        self._authorized = False
        
        logger.info("AzureSecurityScanner initialized")
    
    def authorize(self, confirmation: str = "I_AUTHORIZE_CLOUD_TESTING") -> bool:
        """Authorize testing"""
        if confirmation == "I_AUTHORIZE_CLOUD_TESTING":
            self._authorized = True
            return True
        return False
    
    async def enumerate_storage_accounts(
        self,
        company_names: List[str],
    ) -> List[Dict]:
        """Enumerate Azure storage accounts"""
        if not self._authorized:
            return []
        
        found_accounts = []
        
        # Azure storage account naming: 3-24 chars, lowercase alphanumeric only
        for company in company_names:
            account_name = company.lower().replace('-', '').replace('_', '').replace(' ', '')[:24]
            
            # Test variations
            test_names = [
                account_name,
                f"{account_name}storage",
                f"{account_name}blob",
                f"{account_name}data",
                f"storage{account_name}",
            ]
            
            for name in test_names:
                name = name[:24]  # Max 24 chars
                url = f"https://{name}.blob.core.windows.net/?comp=list"
                
                try:
                    status, response, _ = await self._make_request(url)
                    self.stats['storage_tests'] += 1
                    
                    if status == 200:
                        found_accounts.append({
                            'name': name,
                            'url': f"https://{name}.blob.core.windows.net",
                            'public': True,
                        })
                        
                        vuln = CloudVulnerability(
                            vuln_type=CloudVulnType.AZURE_BLOB_PUBLIC,
                            severity=SeverityLevel.HIGH,
                            provider=CloudProvider.AZURE,
                            resource=f"Storage Account: {name}",
                            region="global",
                            description=f"Azure storage account '{name}' allows public access",
                            remediation="Disable public blob access on storage account",
                            confidence=0.95,
                            cwe_id="CWE-284",
                        )
                        self.vulnerabilities.append(vuln)
                    
                    elif status == 403:
                        found_accounts.append({
                            'name': name,
                            'url': f"https://{name}.blob.core.windows.net",
                            'public': False,
                        })
                
                except Exception:
                    continue
        
        return found_accounts
    
    async def _make_request(self, url: str) -> Tuple[Optional[int], Optional[str], Optional[Dict]]:
        """Make HTTP request"""
        if not AIOHTTP_AVAILABLE:
            return None, None, None
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=30)) as response:
                    text = await response.text()
                    return response.status, text, dict(response.headers)
        except Exception:
            return None, None, None


# =============================================================================
# GCP SECURITY SCANNER
# =============================================================================

class GCPSecurityScanner:
    """
    GCP Security Scanner
    
    Capabilities:
    - GCS bucket enumeration
    - IAM analysis
    - Project security
    """
    
    GCS_URL = "https://storage.googleapis.com/{bucket}"
    
    def __init__(self, config: Optional[CloudSecurityConfig] = None):
        """Initialize GCP security scanner"""
        self.config = config or CloudSecurityConfig()
        self.vulnerabilities: List[CloudVulnerability] = []
        self.stats = defaultdict(int)
        self._authorized = False
        
        logger.info("GCPSecurityScanner initialized")
    
    def authorize(self, confirmation: str = "I_AUTHORIZE_CLOUD_TESTING") -> bool:
        """Authorize testing"""
        if confirmation == "I_AUTHORIZE_CLOUD_TESTING":
            self._authorized = True
            return True
        return False
    
    async def enumerate_gcs_buckets(
        self,
        company_names: List[str],
    ) -> List[Dict]:
        """Enumerate GCS buckets"""
        if not self._authorized:
            return []
        
        found_buckets = []
        
        for company in company_names:
            bucket_names = [
                company.lower(),
                f"{company.lower()}-backup",
                f"{company.lower()}-data",
                f"{company.lower()}-storage",
                f"{company.lower()}-assets",
            ]
            
            for bucket_name in bucket_names:
                url = self.GCS_URL.format(bucket=bucket_name)
                
                try:
                    status, response, _ = await self._make_request(url)
                    
                    if status == 200:
                        found_buckets.append({
                            'name': bucket_name,
                            'url': url,
                            'public': True,
                        })
                        
                        vuln = CloudVulnerability(
                            vuln_type=CloudVulnType.GCP_BUCKET_PUBLIC,
                            severity=SeverityLevel.HIGH,
                            provider=CloudProvider.GCP,
                            resource=f"gs://{bucket_name}",
                            region="global",
                            description=f"GCS bucket '{bucket_name}' allows public access",
                            remediation="Remove allUsers/allAuthenticatedUsers permissions",
                            confidence=0.95,
                            cwe_id="CWE-284",
                        )
                        self.vulnerabilities.append(vuln)
                
                except Exception:
                    continue
        
        return found_buckets
    
    async def _make_request(self, url: str) -> Tuple[Optional[int], Optional[str], Optional[Dict]]:
        """Make HTTP request"""
        if not AIOHTTP_AVAILABLE:
            return None, None, None
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=30)) as response:
                    text = await response.text()
                    return response.status, text, dict(response.headers)
        except Exception:
            return None, None, None


# =============================================================================
# UNIFIED CLOUD SECURITY SCANNER
# =============================================================================

class CloudSecurityScanner:
    """
    Unified Cloud Security Scanner
    
    Multi-cloud security assessment supporting:
    - AWS (S3, IAM, IMDS, Lambda)
    - Azure (Blob, Storage, AD)
    - GCP (GCS, IAM)
    
    README COMPLIANCE:
    - Stealth-First: Minimal API calls, randomized timing
    - RAM-Only: No persistent storage
    - No Telemetry: Zero external reporting
    - Authorization Required: Explicit consent
    """
    
    def __init__(self, config: Optional[CloudSecurityConfig] = None):
        """Initialize unified scanner"""
        self.config = config or CloudSecurityConfig()
        self.aws_scanner = AWSSecurityScanner(self.config)
        self.azure_scanner = AzureSecurityScanner(self.config)
        self.gcp_scanner = GCPSecurityScanner(self.config)
        self._authorized = False
        
        logger.info("CloudSecurityScanner initialized - Multi-cloud support")
    
    def authorize(self, confirmation: str = "I_AUTHORIZE_CLOUD_TESTING") -> bool:
        """Authorize all scanners"""
        if confirmation == "I_AUTHORIZE_CLOUD_TESTING":
            self._authorized = True
            self.aws_scanner.authorize(confirmation)
            self.azure_scanner.authorize(confirmation)
            self.gcp_scanner.authorize(confirmation)
            return True
        return False
    
    async def scan_all(
        self,
        company_names: List[str],
        providers: Optional[List[CloudProvider]] = None,
    ) -> Dict[str, List[CloudVulnerability]]:
        """
        Scan all configured cloud providers
        """
        if not self._authorized:
            logger.error("Scanning not authorized")
            return {}
        
        providers = providers or self.config.providers
        results = {}
        
        for provider in providers:
            if provider == CloudProvider.AWS:
                vulns = await self.aws_scanner.scan(company_names=company_names)
                results['aws'] = vulns
            
            elif provider == CloudProvider.AZURE:
                await self.azure_scanner.enumerate_storage_accounts(company_names)
                results['azure'] = self.azure_scanner.vulnerabilities
            
            elif provider == CloudProvider.GCP:
                await self.gcp_scanner.enumerate_gcs_buckets(company_names)
                results['gcp'] = self.gcp_scanner.vulnerabilities
        
        return results
    
    def get_all_vulnerabilities(self) -> List[CloudVulnerability]:
        """Get vulnerabilities from all scanners"""
        all_vulns = []
        all_vulns.extend(self.aws_scanner.vulnerabilities)
        all_vulns.extend(self.azure_scanner.vulnerabilities)
        all_vulns.extend(self.gcp_scanner.vulnerabilities)
        return all_vulns
    
    def get_report(self, format: str = "json") -> str:
        """Generate unified report"""
        all_vulns = self.get_all_vulnerabilities()
        
        if format == "json":
            return json.dumps({
                'scan_time': datetime.now().isoformat(),
                'total_vulnerabilities': len(all_vulns),
                'by_provider': {
                    'aws': len(self.aws_scanner.vulnerabilities),
                    'azure': len(self.azure_scanner.vulnerabilities),
                    'gcp': len(self.gcp_scanner.vulnerabilities),
                },
                'vulnerabilities': [v.to_dict() for v in all_vulns],
            }, indent=2)
        
        else:
            lines = [
                "=" * 70,
                "RF ARSENAL OS - CLOUD SECURITY SCAN REPORT",
                "=" * 70,
                f"Scan Time: {datetime.now().isoformat()}",
                "",
                "SUMMARY BY PROVIDER:",
                f"  AWS: {len(self.aws_scanner.vulnerabilities)} vulnerabilities",
                f"  Azure: {len(self.azure_scanner.vulnerabilities)} vulnerabilities",
                f"  GCP: {len(self.gcp_scanner.vulnerabilities)} vulnerabilities",
                f"  Total: {len(all_vulns)} vulnerabilities",
                "",
            ]
            
            for vuln in sorted(all_vulns, key=lambda v: list(SeverityLevel).index(v.severity)):
                lines.append(f"\n[{vuln.severity.value.upper()}] [{vuln.provider.value.upper()}] {vuln.vuln_type.value}")
                lines.append(f"  Resource: {vuln.resource}")
                lines.append(f"  Description: {vuln.description}")
            
            return "\n".join(lines)
    
    def clear_results(self):
        """Clear all results"""
        self.aws_scanner.clear_results()
        self.azure_scanner.vulnerabilities = []
        self.gcp_scanner.vulnerabilities = []


# =============================================================================
# CONVENIENCE FUNCTIONS
# =============================================================================

def create_cloud_scanner(
    providers: Optional[List[CloudProvider]] = None,
    proxy: Optional[str] = None,
) -> CloudSecurityScanner:
    """Factory function to create cloud scanner"""
    config = CloudSecurityConfig(
        providers=providers or [CloudProvider.AWS],
        use_proxy=bool(proxy),
        proxy_url=proxy,
    )
    return CloudSecurityScanner(config)


async def quick_cloud_scan(
    company_names: List[str],
    providers: Optional[List[CloudProvider]] = None,
) -> List[CloudVulnerability]:
    """Quick cloud security scan"""
    scanner = create_cloud_scanner(providers)
    scanner.authorize("I_AUTHORIZE_CLOUD_TESTING")
    await scanner.scan_all(company_names, providers)
    return scanner.get_all_vulnerabilities()


# =============================================================================
# MODULE INFO
# =============================================================================

__all__ = [
    # Main classes
    'CloudSecurityScanner',
    'AWSSecurityScanner',
    'AzureSecurityScanner',
    'GCPSecurityScanner',
    'CloudSecurityConfig',
    'CloudVulnerability',
    # Data classes
    'S3Bucket',
    'IAMPolicy',
    'CloudCredential',
    # Enums
    'CloudProvider',
    'CloudVulnType',
    'SeverityLevel',
    'BucketPermission',
    # Convenience functions
    'create_cloud_scanner',
    'quick_cloud_scan',
]

__version__ = '1.0.0'
__author__ = 'RF Arsenal Security Team'


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    async def main():
        print("RF Arsenal OS - Cloud Security Scanner")
        print("=" * 50)
        print("\nCapabilities:")
        print("  - AWS S3 bucket enumeration and security")
        print("  - AWS IAM policy analysis")
        print("  - AWS IMDS exposure testing")
        print("  - Azure blob storage testing")
        print("  - GCP bucket testing")
        print("  - Credential detection")
        print("\nUsage:")
        print("  scanner = create_cloud_scanner([CloudProvider.AWS])")
        print("  scanner.authorize('I_AUTHORIZE_CLOUD_TESTING')")
        print("  await scanner.scan_all(['company-name'])")
    
    asyncio.run(main())
