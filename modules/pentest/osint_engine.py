#!/usr/bin/env python3
"""
RF Arsenal OS - OSINT Engine
============================

Open Source Intelligence gathering with stealth-first design.
Supports domain intel, email harvesting, and leaked credential checks.

STEALTH FEATURES:
- Proxy chain integration
- Rate limiting
- Request fingerprint obfuscation
- RAM-only data storage
- No telemetry

Author: RF Arsenal Security Team
License: Authorized Use Only
"""

import asyncio
import base64
import hashlib
import json
import logging
import os
import random
import re
import socket
import ssl
import time
from dataclasses import dataclass, field

# Optional dependencies - graceful fallback
try:
    import aiohttp
    AIOHTTP_AVAILABLE = True
except ImportError:
    AIOHTTP_AVAILABLE = False

try:
    import dns.resolver
    DNS_AVAILABLE = True
except ImportError:
    DNS_AVAILABLE = False

try:
    import whois
    WHOIS_AVAILABLE = True
except ImportError:
    WHOIS_AVAILABLE = False
from datetime import datetime
from enum import Enum
from typing import Any, Callable, Dict, List, Optional, Set, Tuple
from collections import defaultdict
from urllib.parse import urlparse, urljoin

logger = logging.getLogger(__name__)


class IntelType(Enum):
    """Intelligence types"""
    DOMAIN = "domain"
    IP = "ip"
    EMAIL = "email"
    PERSON = "person"
    ORGANIZATION = "organization"
    PHONE = "phone"
    USERNAME = "username"
    HASH = "hash"
    CREDENTIAL = "credential"
    SOCIAL_MEDIA = "social_media"
    DOCUMENT = "document"
    TECHNOLOGY = "technology"


@dataclass
class IntelResult:
    """Intelligence result"""
    intel_type: IntelType
    source: str
    data: Dict[str, Any]
    confidence: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)
    raw_data: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary"""
        return {
            'type': self.intel_type.value,
            'source': self.source,
            'data': self.data,
            'confidence': self.confidence,
            'timestamp': self.timestamp.isoformat(),
        }


@dataclass
class DomainInfo:
    """Domain intelligence"""
    domain: str
    registrar: Optional[str] = None
    creation_date: Optional[datetime] = None
    expiration_date: Optional[datetime] = None
    updated_date: Optional[datetime] = None
    name_servers: List[str] = field(default_factory=list)
    registrant: Optional[str] = None
    registrant_email: Optional[str] = None
    registrant_country: Optional[str] = None
    admin_email: Optional[str] = None
    tech_email: Optional[str] = None
    status: List[str] = field(default_factory=list)
    dnssec: bool = False
    # DNS records
    a_records: List[str] = field(default_factory=list)
    aaaa_records: List[str] = field(default_factory=list)
    mx_records: List[str] = field(default_factory=list)
    txt_records: List[str] = field(default_factory=list)
    ns_records: List[str] = field(default_factory=list)
    cname_records: List[str] = field(default_factory=list)
    soa_record: Optional[str] = None
    # Subdomains
    subdomains: List[str] = field(default_factory=list)
    # Technologies detected
    technologies: List[str] = field(default_factory=list)
    # SSL/TLS info
    ssl_issuer: Optional[str] = None
    ssl_subject: Optional[str] = None
    ssl_expiry: Optional[datetime] = None


@dataclass
class EmailInfo:
    """Email intelligence"""
    email: str
    valid: bool = False
    disposable: bool = False
    deliverable: bool = False
    catch_all: bool = False
    domain_info: Optional[DomainInfo] = None
    breaches: List[str] = field(default_factory=list)
    social_profiles: List[str] = field(default_factory=list)
    first_seen: Optional[datetime] = None
    last_seen: Optional[datetime] = None


@dataclass 
class OSINTConfig:
    """OSINT engine configuration"""
    # Request settings
    timeout: float = 30.0
    max_retries: int = 3
    delay_min: float = 1.0
    delay_max: float = 3.0
    
    # Proxy settings
    use_proxy: bool = False
    proxy_url: Optional[str] = None
    
    # Module settings
    enable_whois: bool = True
    enable_dns: bool = True
    enable_ssl: bool = True
    enable_subdomains: bool = True
    enable_email_verify: bool = True
    enable_breach_check: bool = True
    enable_social_lookup: bool = True
    
    # Rate limiting
    rate_limit: int = 10  # Requests per minute
    
    # Stealth
    randomize_user_agent: bool = True


class OSINTEngine:
    """
    Open Source Intelligence Engine
    
    Features:
    - Domain intelligence (WHOIS, DNS, SSL)
    - Subdomain enumeration
    - Email harvesting and verification
    - Breach data lookup
    - Social media discovery
    - Technology fingerprinting
    
    STEALTH COMPLIANCE:
    - All data stored in RAM only
    - Proxy support for anonymity
    - Rate limiting
    - No telemetry
    """
    
    # User agents for stealth
    USER_AGENTS = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
    ]
    
    # Common subdomains to check
    COMMON_SUBDOMAINS = [
        "www", "mail", "ftp", "localhost", "webmail", "smtp", "pop", "ns1", "ns2",
        "ns", "dns", "dns1", "dns2", "mx", "mx1", "mx2", "remote", "blog", "shop",
        "ssl", "secure", "vpn", "admin", "administrator", "test", "dev", "staging",
        "api", "app", "apps", "portal", "forum", "forums", "m", "mobile", "old",
        "new", "beta", "alpha", "demo", "preview", "static", "assets", "cdn",
        "img", "images", "video", "media", "download", "downloads", "support",
        "help", "docs", "documentation", "wiki", "news", "store", "cart", "pay",
        "payment", "checkout", "billing", "account", "accounts", "login", "signin",
        "signup", "register", "auth", "oauth", "sso", "status", "monitor", "health",
        "metrics", "analytics", "tracking", "ads", "adserver", "marketing", "promo",
        "email", "newsletters", "subscribe", "unsubscribe", "git", "gitlab", "github",
        "svn", "hg", "mercurial", "jenkins", "ci", "cd", "build", "deploy", "stage",
        "prod", "production", "uat", "qa", "sandbox", "internal", "intranet", "extranet",
        "partner", "partners", "vendor", "vendors", "client", "clients", "customer",
    ]
    
    # Technology signatures
    TECH_SIGNATURES = {
        'WordPress': [r'wp-content', r'wp-includes', r'/wp-'],
        'Drupal': [r'Drupal', r'/sites/default/', r'drupal.js'],
        'Joomla': [r'Joomla!', r'/administrator/', r'/components/'],
        'Magento': [r'Magento', r'MAGE', r'/skin/frontend/'],
        'Shopify': [r'Shopify', r'cdn.shopify.com'],
        'nginx': [r'nginx'],
        'Apache': [r'Apache', r'apache'],
        'IIS': [r'Microsoft-IIS', r'ASP.NET'],
        'PHP': [r'X-Powered-By: PHP', r'\.php'],
        'Node.js': [r'X-Powered-By: Express'],
        'Django': [r'csrfmiddlewaretoken', r'django'],
        'Rails': [r'X-Powered-By: Phusion Passenger', r'Rails'],
        'React': [r'react', r'_reactRootContainer'],
        'Angular': [r'ng-', r'angular'],
        'Vue.js': [r'vue', r'v-'],
        'jQuery': [r'jquery'],
        'Bootstrap': [r'bootstrap'],
        'Cloudflare': [r'cloudflare', r'__cf'],
        'AWS': [r'amazonaws.com', r'aws'],
        'Google Analytics': [r'google-analytics.com', r'gtag'],
        'reCAPTCHA': [r'recaptcha', r'google.com/recaptcha'],
    }
    
    # Disposable email domains (partial list)
    DISPOSABLE_DOMAINS = {
        'tempmail.com', 'guerrillamail.com', 'mailinator.com', '10minutemail.com',
        'throwaway.email', 'temp-mail.org', 'fakeinbox.com', 'getnada.com',
        'maildrop.cc', 'yopmail.com', 'sharklasers.com', 'trashmail.com',
    }
    
    def __init__(self, config: Optional[OSINTConfig] = None):
        """Initialize OSINT engine"""
        self.config = config or OSINTConfig()
        self.results: List[IntelResult] = []
        self.domains: Dict[str, DomainInfo] = {}
        self.emails: Dict[str, EmailInfo] = {}
        self._lock = asyncio.Lock()
        self._request_times: List[float] = []
        self.stats = defaultdict(int)
        
        logger.info("OSINTEngine initialized - RAM-only operation")
    
    def _get_user_agent(self) -> str:
        """Get random user agent"""
        if self.config.randomize_user_agent:
            return random.choice(self.USER_AGENTS)
        return self.USER_AGENTS[0]
    
    async def _rate_limit(self):
        """Apply rate limiting"""
        now = time.time()
        
        # Remove old request times
        self._request_times = [t for t in self._request_times if now - t < 60]
        
        # Check rate limit
        if len(self._request_times) >= self.config.rate_limit:
            wait_time = 60 - (now - self._request_times[0])
            if wait_time > 0:
                logger.debug(f"Rate limiting: waiting {wait_time:.1f}s")
                await asyncio.sleep(wait_time)
        
        self._request_times.append(time.time())
    
    async def _delay(self):
        """Apply random delay"""
        delay = random.uniform(self.config.delay_min, self.config.delay_max)
        await asyncio.sleep(delay)
    
    async def _make_request(
        self,
        url: str,
        method: str = "GET",
        headers: Optional[Dict] = None,
        data: Optional[Dict] = None,
    ) -> Tuple[int, str, Dict]:
        """Make HTTP request with stealth features"""
        await self._rate_limit()
        await self._delay()
        
        request_headers = {
            "User-Agent": self._get_user_agent(),
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
            "Accept-Language": "en-US,en;q=0.5",
        }
        
        if headers:
            request_headers.update(headers)
        
        try:
            ssl_context = ssl.create_default_context()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE
            
            connector = aiohttp.TCPConnector(ssl=ssl_context)
            timeout = aiohttp.ClientTimeout(total=self.config.timeout)
            
            proxy = self.config.proxy_url if self.config.use_proxy else None
            
            async with aiohttp.ClientSession(
                connector=connector,
                timeout=timeout,
                headers=request_headers,
            ) as session:
                if method.upper() == "GET":
                    async with session.get(url, proxy=proxy) as response:
                        text = await response.text()
                        return response.status, text, dict(response.headers)
                elif method.upper() == "POST":
                    async with session.post(url, data=data, proxy=proxy) as response:
                        text = await response.text()
                        return response.status, text, dict(response.headers)
                        
        except Exception as e:
            logger.debug(f"Request failed: {e}")
            return 0, "", {}
    
    async def gather_domain_intel(self, domain: str) -> DomainInfo:
        """
        Gather comprehensive domain intelligence
        
        Args:
            domain: Target domain
            
        Returns:
            DomainInfo object
        """
        logger.info(f"Gathering intel on domain: {domain}")
        
        domain_info = DomainInfo(domain=domain)
        
        # WHOIS lookup
        if self.config.enable_whois:
            await self._whois_lookup(domain_info)
        
        # DNS enumeration
        if self.config.enable_dns:
            await self._dns_lookup(domain_info)
        
        # SSL certificate info
        if self.config.enable_ssl:
            await self._ssl_lookup(domain_info)
        
        # Subdomain enumeration
        if self.config.enable_subdomains:
            await self._enumerate_subdomains(domain_info)
        
        # Technology fingerprinting
        await self._fingerprint_technologies(domain_info)
        
        # Store results
        async with self._lock:
            self.domains[domain] = domain_info
            self.results.append(IntelResult(
                intel_type=IntelType.DOMAIN,
                source="domain_intel",
                data=domain_info.__dict__,
                confidence=0.9,
            ))
        
        self.stats['domains_scanned'] += 1
        return domain_info
    
    async def _whois_lookup(self, domain_info: DomainInfo):
        """Perform WHOIS lookup"""
        try:
            w = whois.whois(domain_info.domain)
            
            domain_info.registrar = w.registrar
            domain_info.creation_date = w.creation_date if not isinstance(w.creation_date, list) else w.creation_date[0]
            domain_info.expiration_date = w.expiration_date if not isinstance(w.expiration_date, list) else w.expiration_date[0]
            domain_info.updated_date = w.updated_date if not isinstance(w.updated_date, list) else w.updated_date[0]
            domain_info.name_servers = w.name_servers or []
            domain_info.registrant = w.org or w.name
            domain_info.registrant_email = w.emails[0] if w.emails else None
            domain_info.registrant_country = w.country
            domain_info.status = w.status if isinstance(w.status, list) else [w.status] if w.status else []
            domain_info.dnssec = bool(w.dnssec)
            
            logger.debug(f"WHOIS lookup complete for {domain_info.domain}")
            
        except Exception as e:
            logger.debug(f"WHOIS lookup failed: {e}")
    
    async def _dns_lookup(self, domain_info: DomainInfo):
        """Perform DNS lookups"""
        resolver = dns.resolver.Resolver()
        resolver.timeout = 5
        resolver.lifetime = 5
        
        record_types = {
            'A': 'a_records',
            'AAAA': 'aaaa_records',
            'MX': 'mx_records',
            'TXT': 'txt_records',
            'NS': 'ns_records',
            'CNAME': 'cname_records',
        }
        
        for record_type, attr in record_types.items():
            try:
                answers = resolver.resolve(domain_info.domain, record_type)
                records = [str(r) for r in answers]
                setattr(domain_info, attr, records)
            except Exception:
                pass
        
        # SOA record
        try:
            answers = resolver.resolve(domain_info.domain, 'SOA')
            domain_info.soa_record = str(answers[0])
        except Exception:
            pass
        
        logger.debug(f"DNS lookup complete for {domain_info.domain}")
    
    async def _ssl_lookup(self, domain_info: DomainInfo):
        """Get SSL certificate information"""
        try:
            ssl_context = ssl.create_default_context()
            
            conn = ssl_context.wrap_socket(
                socket.socket(socket.AF_INET),
                server_hostname=domain_info.domain
            )
            conn.settimeout(10)
            conn.connect((domain_info.domain, 443))
            
            cert = conn.getpeercert()
            conn.close()
            
            # Extract issuer
            issuer = dict(x[0] for x in cert.get('issuer', []))
            domain_info.ssl_issuer = issuer.get('organizationName', '')
            
            # Extract subject
            subject = dict(x[0] for x in cert.get('subject', []))
            domain_info.ssl_subject = subject.get('commonName', '')
            
            # Expiry date
            expiry_str = cert.get('notAfter', '')
            if expiry_str:
                domain_info.ssl_expiry = datetime.strptime(
                    expiry_str, '%b %d %H:%M:%S %Y %Z'
                )
            
            logger.debug(f"SSL lookup complete for {domain_info.domain}")
            
        except Exception as e:
            logger.debug(f"SSL lookup failed: {e}")
    
    async def _enumerate_subdomains(self, domain_info: DomainInfo):
        """Enumerate subdomains"""
        found_subdomains = []
        
        # DNS brute force
        resolver = dns.resolver.Resolver()
        resolver.timeout = 2
        resolver.lifetime = 2
        
        async def check_subdomain(subdomain: str):
            full_domain = f"{subdomain}.{domain_info.domain}"
            try:
                answers = resolver.resolve(full_domain, 'A')
                if answers:
                    found_subdomains.append(full_domain)
            except Exception:
                pass
        
        # Check common subdomains
        tasks = [check_subdomain(sub) for sub in self.COMMON_SUBDOMAINS[:50]]
        await asyncio.gather(*tasks, return_exceptions=True)
        
        domain_info.subdomains = found_subdomains
        logger.debug(f"Found {len(found_subdomains)} subdomains for {domain_info.domain}")
    
    async def _fingerprint_technologies(self, domain_info: DomainInfo):
        """Detect technologies used by domain"""
        try:
            status, html, headers = await self._make_request(f"https://{domain_info.domain}")
            
            if status != 200:
                status, html, headers = await self._make_request(f"http://{domain_info.domain}")
            
            if not html:
                return
            
            # Check signatures
            detected = []
            
            for tech, patterns in self.TECH_SIGNATURES.items():
                for pattern in patterns:
                    if re.search(pattern, html, re.IGNORECASE):
                        detected.append(tech)
                        break
                    
                    # Check headers
                    for header_value in headers.values():
                        if re.search(pattern, str(header_value), re.IGNORECASE):
                            detected.append(tech)
                            break
            
            domain_info.technologies = list(set(detected))
            logger.debug(f"Detected technologies: {domain_info.technologies}")
            
        except Exception as e:
            logger.debug(f"Technology fingerprinting failed: {e}")
    
    async def gather_email_intel(self, email: str) -> EmailInfo:
        """
        Gather email intelligence
        
        Args:
            email: Target email address
            
        Returns:
            EmailInfo object
        """
        logger.info(f"Gathering intel on email: {email}")
        
        email_info = EmailInfo(email=email)
        
        # Extract domain
        domain = email.split('@')[1] if '@' in email else None
        
        if not domain:
            return email_info
        
        # Check if disposable
        email_info.disposable = domain.lower() in self.DISPOSABLE_DOMAINS
        
        # Email validation
        if self.config.enable_email_verify:
            email_info.valid = await self._verify_email(email)
            email_info.deliverable = await self._check_deliverable(email, domain)
        
        # Get domain info
        if domain not in self.domains:
            email_info.domain_info = await self.gather_domain_intel(domain)
        else:
            email_info.domain_info = self.domains[domain]
        
        # Store results
        async with self._lock:
            self.emails[email] = email_info
            self.results.append(IntelResult(
                intel_type=IntelType.EMAIL,
                source="email_intel",
                data={'email': email, 'valid': email_info.valid, 'disposable': email_info.disposable},
                confidence=0.8,
            ))
        
        self.stats['emails_checked'] += 1
        return email_info
    
    async def _verify_email(self, email: str) -> bool:
        """Verify email format"""
        pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        return bool(re.match(pattern, email))
    
    async def _check_deliverable(self, email: str, domain: str) -> bool:
        """Check if email is deliverable via MX lookup"""
        try:
            resolver = dns.resolver.Resolver()
            resolver.timeout = 5
            resolver.lifetime = 5
            
            # Get MX records
            mx_records = resolver.resolve(domain, 'MX')
            
            if mx_records:
                return True
                
        except Exception:
            pass
        
        return False
    
    async def harvest_emails(self, domain: str, depth: int = 2) -> List[str]:
        """
        Harvest emails from domain
        
        Args:
            domain: Target domain
            depth: Crawl depth
            
        Returns:
            List of discovered emails
        """
        logger.info(f"Harvesting emails from: {domain}")
        
        discovered_emails = set()
        visited_urls = set()
        to_visit = [f"https://{domain}", f"http://{domain}"]
        current_depth = 0
        
        email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
        
        while to_visit and current_depth < depth:
            current_batch = to_visit[:20]
            to_visit = to_visit[20:]
            
            for url in current_batch:
                if url in visited_urls:
                    continue
                
                visited_urls.add(url)
                
                status, html, headers = await self._make_request(url)
                
                if not html:
                    continue
                
                # Extract emails
                emails = re.findall(email_pattern, html)
                for email in emails:
                    if domain.lower() in email.lower():
                        discovered_emails.add(email.lower())
                
                # Extract links for next depth
                if current_depth < depth - 1:
                    link_pattern = r'href=["\']([^"\']+)["\']'
                    links = re.findall(link_pattern, html)
                    
                    for link in links:
                        absolute_url = urljoin(url, link)
                        parsed = urlparse(absolute_url)
                        
                        if domain in parsed.netloc and absolute_url not in visited_urls:
                            to_visit.append(absolute_url)
            
            current_depth += 1
        
        email_list = list(discovered_emails)
        logger.info(f"Found {len(email_list)} emails from {domain}")
        
        self.stats['emails_harvested'] += len(email_list)
        return email_list
    
    async def lookup_ip(self, ip: str) -> Dict[str, Any]:
        """
        Lookup IP address information
        
        Args:
            ip: IP address
            
        Returns:
            IP intelligence data
        """
        logger.info(f"Looking up IP: {ip}")
        
        result = {
            'ip': ip,
            'reverse_dns': None,
            'asn': None,
            'org': None,
            'country': None,
            'city': None,
        }
        
        # Reverse DNS
        try:
            result['reverse_dns'] = socket.gethostbyaddr(ip)[0]
        except Exception:
            pass
        
        # IP info from free API (no API key needed)
        try:
            status, data, headers = await self._make_request(f"http://ip-api.com/json/{ip}")
            if status == 200:
                info = json.loads(data)
                result['country'] = info.get('country')
                result['city'] = info.get('city')
                result['org'] = info.get('org')
                result['asn'] = info.get('as')
        except Exception:
            pass
        
        # Store result
        async with self._lock:
            self.results.append(IntelResult(
                intel_type=IntelType.IP,
                source="ip_lookup",
                data=result,
                confidence=0.9,
            ))
        
        self.stats['ips_looked_up'] += 1
        return result
    
    async def search_breaches(self, email: str) -> List[str]:
        """
        Check if email appears in known breaches
        
        NOTE: This is a basic check. For production use,
        integrate with HaveIBeenPwned API or similar service.
        
        Args:
            email: Email to check
            
        Returns:
            List of breach names
        """
        logger.info(f"Checking breaches for: {email}")
        
        # SHA1 hash for k-anonymity check (HIBP API style)
        sha1 = hashlib.sha1(email.lower().encode()).hexdigest().upper()
        prefix = sha1[:5]
        suffix = sha1[5:]
        
        breaches = []
        
        # Note: In production, use actual HIBP API with proper rate limiting
        # This is a placeholder that shows the approach
        
        async with self._lock:
            self.results.append(IntelResult(
                intel_type=IntelType.CREDENTIAL,
                source="breach_check",
                data={'email': email, 'breaches': breaches, 'sha1_prefix': prefix},
                confidence=0.5,
            ))
        
        return breaches
    
    async def search_social_profiles(self, username: str) -> Dict[str, str]:
        """
        Search for social media profiles
        
        Args:
            username: Username to search
            
        Returns:
            Dictionary of platform: profile_url
        """
        logger.info(f"Searching social profiles for: {username}")
        
        platforms = {
            'twitter': f'https://twitter.com/{username}',
            'github': f'https://github.com/{username}',
            'instagram': f'https://instagram.com/{username}',
            'linkedin': f'https://linkedin.com/in/{username}',
            'facebook': f'https://facebook.com/{username}',
            'reddit': f'https://reddit.com/user/{username}',
            'pinterest': f'https://pinterest.com/{username}',
            'medium': f'https://medium.com/@{username}',
            'youtube': f'https://youtube.com/@{username}',
        }
        
        found_profiles = {}
        
        for platform, url in platforms.items():
            status, html, headers = await self._make_request(url)
            
            # Basic existence check (status 200 = likely exists)
            if status == 200:
                # Additional validation could check for profile content
                found_profiles[platform] = url
        
        async with self._lock:
            self.results.append(IntelResult(
                intel_type=IntelType.SOCIAL_MEDIA,
                source="social_search",
                data={'username': username, 'profiles': found_profiles},
                confidence=0.7,
            ))
        
        self.stats['social_searches'] += 1
        return found_profiles
    
    def get_stats(self) -> Dict[str, Any]:
        """Get engine statistics"""
        return {
            'domains_scanned': self.stats['domains_scanned'],
            'emails_checked': self.stats['emails_checked'],
            'emails_harvested': self.stats['emails_harvested'],
            'ips_looked_up': self.stats['ips_looked_up'],
            'social_searches': self.stats['social_searches'],
            'total_results': len(self.results),
        }
    
    def get_results(self, intel_type: Optional[IntelType] = None) -> List[IntelResult]:
        """Get results, optionally filtered by type"""
        if intel_type:
            return [r for r in self.results if r.intel_type == intel_type]
        return self.results
    
    def get_report(self, format: str = "text") -> str:
        """Generate OSINT report"""
        if format == "json":
            return json.dumps({
                'timestamp': datetime.now().isoformat(),
                'statistics': self.get_stats(),
                'domains': {d: info.__dict__ for d, info in self.domains.items()},
                'emails': {e: info.__dict__ for e, info in self.emails.items()},
            }, indent=2, default=str)
        
        # Text format
        lines = [
            "=" * 60,
            "RF ARSENAL OS - OSINT REPORT",
            "=" * 60,
            f"Generated: {datetime.now().isoformat()}",
            "",
            "STATISTICS:",
            f"  Domains Scanned: {self.stats['domains_scanned']}",
            f"  Emails Checked: {self.stats['emails_checked']}",
            f"  Emails Harvested: {self.stats['emails_harvested']}",
            "",
        ]
        
        if self.domains:
            lines.append("DOMAINS:")
            lines.append("-" * 40)
            
            for domain, info in self.domains.items():
                lines.append(f"\n{domain}:")
                if info.registrar:
                    lines.append(f"  Registrar: {info.registrar}")
                if info.a_records:
                    lines.append(f"  A Records: {', '.join(info.a_records[:3])}")
                if info.technologies:
                    lines.append(f"  Technologies: {', '.join(info.technologies)}")
                if info.subdomains:
                    lines.append(f"  Subdomains: {len(info.subdomains)} found")
        
        lines.append("\n" + "=" * 60)
        return "\n".join(lines)
    
    def clear_results(self):
        """Clear all results from RAM"""
        self.results = []
        self.domains = {}
        self.emails = {}
        self.stats = defaultdict(int)
        logger.info("OSINT results cleared from RAM")


# Quick functions
async def domain_recon(domain: str) -> DomainInfo:
    """Quick domain reconnaissance"""
    engine = OSINTEngine()
    return await engine.gather_domain_intel(domain)


async def email_recon(email: str) -> EmailInfo:
    """Quick email reconnaissance"""
    engine = OSINTEngine()
    return await engine.gather_email_intel(email)


async def harvest_domain_emails(domain: str) -> List[str]:
    """Quick email harvesting"""
    engine = OSINTEngine()
    return await engine.harvest_emails(domain)


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    async def main():
        engine = OSINTEngine()
        
        # Example domain recon
        domain_info = await engine.gather_domain_intel("example.com")
        print(f"Domain: {domain_info.domain}")
        print(f"Technologies: {domain_info.technologies}")
        print(f"Subdomains: {len(domain_info.subdomains)}")
    
    asyncio.run(main())
